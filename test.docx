네 그러면 분석 과제에 대한 발표 시작하겠습니다. 제가 맡은 분석 과제는 종목 정보 임베딩 및 유사도 평가라는 과제입니다.

발표 순서는 과제에 대한 설명과 접근 전략, 그리고 데이터 생성과 전처리, 이후 종목 정보 임베딩과 결과 및 활용 방안 순으로 진행하겠습니다.

먼저 과제에 대한 간단한 설명입니다.

제가 맡은 과제는 종목 정보 임베딩 및 유사도 평가 과제입니다. 나중에 추천 서비스 등에서의 활용을 위해 종목을 벡터로 임베딩하는 로직을 설계하고, 각 벡터들이 실제로 종목 간 관계를 잘 반영하는지를 확인하는 과제였습니다.

여기서 임베딩이란, 쉽게 말해서 유사한 객체들이 실제로 가까이 위치하도록 객체를 저차원의 벡터로 투영하는 것으로, 객체간의 분별을 위한 인코딩과는 다른 개념입니다.

그렇다면 이 과제를 어떻게 접근하여 해결했는지 제가 수립한 접근 전략을 말씀드리겠습니다.

설명드렸던 것처럼 임베딩이란, 유사한 객체들이 semantic space 상에서 근처에 위치하도록 하는 것이 가장 중요합니다. 따라서 종목을 임베딩 하려면 유사한 객체, 즉 유사한 종목이 무엇인지를 먼저 정의해야 한다고 생각했습니다.

이를 위해 다음의 세 가지 시나리오를 비교해보았습니다.

먼저 같은 업종이면 유사한 종목이라고 보는 시나리오입니다. 하지만 각 종목별 업종 구분코드가 명확하지 않다는 문제가 있었고, 또한 하나의 사업만을 영위하는 종목이 아니거나 지주 종목 등 여러 계열사가 모인 경우 하나의 업종으로 분류하기 어려웠습니다. 가장 결정적으로는, 이 시나리오를 택한다면 굳이 임베딩이 필요없이 업종코드가 같은 종목을 추천하면 되기 때문에 과제에 적합하지 않다고 판단했습니다.

두 번째는 동일한 이슈에 관련된 종목을 유사한 종목이라고 보는 것입니다. 이는 매우 그럴듯한 시나리오였는데, 예를들면 2차전지라는 최근 이슈와 관련된 종목들이라면 유사한 종목이라고 볼 수 있기 때문입니다. 그러나 이 때 “최근 이슈”란 과연 무엇인지를 정의해야하고, 또 그와 관련된 종목을 어떻게 판단할 것인지 주관적인 정의가 필요했습니다. Hive의 데이터 중 뉴스 기사별 언급된 종목이 정리된 테이블이 있긴 하지만, 모든 결과를 신뢰하기 어려웠고 또한 이슈라는 것은 매번 바뀌며 받아들이는 사람마다 영향력이 다르기 때문에 주관성이 지나치게 개입된다 판단하여 배재했습니다.
마지막 시나리오는 가격흐름이 비슷한 종목을 유사한 종목이라고 보는 가정입니다. 종목의 가격 흐름에는 이슈나 업종뿐만 아니라 다양한 요소가 영향을 미치기 때문에, 가장 종합적이고 함축적인 정보라고 볼 수 있습니다. 따라서 특정 기간 동안 비슷한 가격흐름을 보이는 종목이라면 유사한 종목이라 정의할 수 있을 거라 판단했습니다.

또한 향후 추천 서비스 등 대고객 서비스로까지 연결될 경우, 임베딩에 따른 추천 결과의 설명력과 안정성을 위해서 수치화할 수 있는 기준이 필요하다 판단했고, 따라서 마지막 시나리오였던, 가격흐름 기반의 종목 유사성 기준을 선택했습니다.

유사 종목을 정의했으니, 어떻게 임베딩할지 방법론을 따져볼 차례입니다. 저는 가장 대표적인 객체 임베딩 알고리즘인 Word2vec에 주목했습니다. Word2vec은 각 단어를 객체로 두어 단어와 단어 사이의 관계를 담은 벡터를 뽑아내는 임베딩 학습 방법입니다. 이 알고리즘은 한가지 가정을 갖고 출발하는데요, 바로 비슷한 문맥에서 등장하는 단어는 비슷한 의미를 지닌 단어라는 가정입니다. 아래 예시에서 강아지는 이라는 단어는 주변 문맥의 단어가 있는, 귀여운, 털이, 복슬복슬하다이고, 고양이는 이라는 단어 역시 주변 문맥 단어에 있는, 귀여운이라는 단어가 포함되므로, 강아지와 고양이 두 단어는 비슷한 문맥에서 등장하므로 비슷한 의미를 갖는다고 word2vec은 가정합니다. 반대로 스마트폰이라는 단어는 주변 문맥 단어가 고양이, 강아지와 다르기 때문에 word2vec은 이 단어들이 유사성이 없다고 판단하는 방향으로 학습됩니다.

저는 이 단어 객체를 그대로 종목 객체로 치환하면 어떨까라는 생각을 해보았습니다. 가격흐름이 비슷한 종목들을 나열한다면 마치 단어들의 나열, 즉 문맥이라 볼 수 있게 되고, 따라서 이 문맥상 주변 종목들이 비슷한 두 종목을 유사한 종목으로 정의할 수 있다고 판단했습니다. 따라서 앞서 정의한 기준에 따라 각 종목별로 비슷한 주변 종목들을 두고, word2vec 알고리즘을 활용해 그 관계를 학습하게 한다면, 주변 종목이 비슷한 종목끼리 유사한 종목으로 표현되도록 벡터를 뽑을 수 있다는 전략을 세웠습니다.

이 전략을 실행으로 옮기기 위해서 어떻게 데이터를 만들었고 전처리했는지에 대한 내용을 말씀드리겠습니다.

제가 사용한 테이블은 이 세 가지입니다. 모두 상품영역의 테이블로, 신일별시장주가, 종목기본, 그리고 일별시장종목별업종 테이블입니다. 첫번째 테이블에서는 매 거래일별 종목코드와 거래일자, 그리고 종가 컬럼을, 두 번째 테이블에서는 종목 한글명 컬럼을, 세번째 테이블에서는 업종구분코드를 가져왔습니다.

하이브 쿼리를 사용해서 세 테이블을 조인해서 모델링에 사용할 데이터셋을 만들었구요, 모두 종목코드를 기준으로 조인해주었습니다. 거래일자 컬럼으로 기간을 걸러내서 지난주 기준 1년간의 거래만을 추출했고, 또 추천 종목에 거래 정지 중인 종목이 나오면 안되므로 지난주 금요일 기준 거래량이 0건인 종목을 거래중지 종목으로 보아 제거했습니다. 또한 RGS_MKT_CD 컬럼으로 KSE와 KOSDAQ에 상장된 종목만을 남겼고, 이 때 종목 중분류 코드와 종목 코드의 패턴을 찾아서 ETF나 신주인수권증서, 우선주 등을 모두 제거했습니다. 
그렇게 만들어진 raw 데이터는 다음과 같습니다. 코스피와 코스닥 각각 유사종목을 추출할 것이기 때문에 두 테이블을 모두 만들었고, 종목별로 매 거래일마다의 종가 정보가 들어있는 데이터가 되었습니다. 

다음은 이 데이터를 사용해서 종가 차이에 따른 가격 흐름 데이터를 만들었습니다. 여기서 가격 흐름이란, 어제 종가대비 오늘 종가가 얼마나 올랐는지 또는 떨어졌는지를 의미합니다. 따라서 각 종목별로 거래일마다 직전거래일대비 종가등락률을 계산해서 넣어주었습니다. 

예를 들면 첫 번째 셀의 수치는 2022년 8월 22일 A000040 종목의 종가인 714원이 그 전 거래일인 2022년 8월 19일의 종가인 713에 비해 0.14% 오른 가격임을 의미합니다. 당연히 이 데이터프레임은 거래일 by 종목개수 만큼의 크기를 갖게 되고, 코스피 상장 종목 중 채권과 우선주 등이 모두 제거되어 681개의 종목만 남게 되었습니다. 코스닥 상장 종목에도 같은 과정을 거쳐주었지만, 슬라이드 공간을 고려해 지금부터는 코스피 상장 종목의 데이터만 예시로 보여드리겠습니다.

가격흐름을 계산했으니 주변종목을 골라낼 차례입니다. Word2vec알고리즘이 잘 학습하려면 비슷한 종목이 주변에 있어야 하고, 저는 이미 비슷한 종목이란 가격흐름이 비슷한 종목이라는 정의를 앞서서 해두었습니다. 따라서 가격 흐름의 퍼센트포인트 차이가 가장 작은 종목들을 가격흐름이 비슷한 종목이라보고, 주변 종목으로 두었습니다. 그리고 이 때 종가가 전거래일대비 상승했는지 하락했는지도 따져주었는데요, 상승한 종목은 상승한 종목간의 가격흐름 차이만보고, 하락한 종목은 하락한 종목간의 차이만 보아서, 그 차이가 가장 작은 순서대로 sort를 해주었습니다. 예를 들면 2022년 8월 22일에 A000040종목은 전 거래일대비 종가가 상승했으니, 종가가 상승한 다른 종목들인 A000070, 80, 383800 종목과 가격흐름 차이를 비교합니다. 이 때 A000070과의 가격흐름차이가 A383800과의 가격흐름차이보다 크기 때문에 A000040의 주변종목은 A383800이 되는 방식입니다.
이렇게 각 종목별로 모든 거래일마다 가장 종가변동차이가 작은 상위 5%의 종목들을 추려서 각 종목들의 인덱스를 매핑해주었습니다. 그 결과 총 246일의 거래일 동안 681개 종목의 주변종목 조합이 총 167,526개 생겨났습니다. 

하지만 특정 거래일에 가격흐름차이가 가장 작다고 하더라도 그 종목을 모두 주변종목으로 둘 수는 없습니다. 한 번 가격 흐름이 비슷했다고 주변종목은 아닐 수 있기 때문입니다. 따라서 246일의 전체 거래일 동안 각 종목별로 주변종목으로 매핑된 종목들의 카운트를 세서, 가장 자주 주변종목으로 매핑된 종목을 고를 수 있게끔 카운트 데이터 프레임을 만들었습니다. 이 때 자기 자신과의 가격차이는 항상 0이기 때문에, 항상 주변종목으로 들어가게 되는데, 이는 당연한 결과이기 때문에 자기 자신의 카운트는 0으로 맞춰주었습니다. 결과적으로 종목수 by 종목수만큼의 카운트 데이터프레임이 만들어졌습니다.

이제 이 데이터를 가지고 종목 정보를 임베딩해보겠습니다.

Word2vec알고리즘은 CBOW와 Skip-Gram이라는 두 가지 학습방식이 있습니다. 전자는 주변단어로 중심단어를 예측해나가며 임베딩을 업데이트하는 방식이고 후자는 중심단어로 주변단어를 예측해나가며 임베딩을 업데이트하는 방식입니다. 이렇게 단어와 단어 사이 관계를 예측해나가면서, 비슷한 문맥을 가진 단어들은 거리적으로 가까운 임베딩을 갖게 됩니다. 이 두 가지 방식 중 여러 실험과 논문을 비교해본 결과 스킵그램을 활용하는 것이 더 성능이 좋다는 결론을 내려, 해당 방식을 차용했습니다.

다음은 스킵그램의 학습법을 그림으로 표현한 것입니다. 중심단어와 주변단어 각각이 준비되면, 각 단어를 원핫 인코딩한 후에 중심단어를 인풋으로, 주변단어를 아웃풋으로 두는 싱글 레이어 인공신경망을 구축합니다. 즉 멀티클래스분류를 해결하는 인공신경망이 학습해나가며 웨이트 매트릭스가 업데이트되는 방식입니다.

따라서 스킵 그램 알고리즘은 전체 단어 집합 크기만큼의 다중 클래스 분류를 수행해야하고, 이는 연산량 측면에서 매우 비효율적입니다. 이를 해결하는 방법으로 네거티브 샘플링이라는 방법이 있는데요, 주변단어를 직접 예측하는 다중분류예측대신 중심단어와 특정단어가 주변 관계인지 아닌지를 예측하는 이진분류문제로 치환하는 방식입니다. 이를 위해서는 중심단어와 주변단어를 두고 두 단어기 주변관계인지 아닌지를 라벨로 두는 데이터셋을 구축해야합니다. 이후 중심단어와 주변단어가 모두 인풋으로 들어가서, 모델이 이진 분류를 수행하면서 웨이트 매트릭스가 업데이트 됩니다.

저는 네거티브 샘플링을 통한 스킵그램 방식을 선택했고, 따라서 이를 위한 데이터셋을 만들어주었습니다. 이 때 앞서 만들어둔 카운트 데이터프레임을 사용해서, 사용자가 입력한 윈도우 값에 따라 상위 n개의 주변종목을 추출했고, 주변 종목이 아닌 종목 중 랜덤하게 샘플링해서 네거티브 샘플링 데이터셋을 만들었습니다. 윈도우란 몇 개의 종목을 주변종목으로 볼 것인지 조절하는 학습 파라미터로, 예시처럼 데이터셋의 크기를 결정하게 됩니다. 

제가 만든 모델의 구조는 다음과 같습니다. 중심 종목 삼성전자와 주변종목 SK하이닉스가 원핫인코딩 형태로 동시에 모델의 인풋으로 들어갑니다. 두 인풋은 각각의 임베딩 매트릭스와 곱해져 룩업 과정을 통해 벡터로 변환되고, 두 벡터가 내적을 하여 스칼라를 뽑아 시그모이드 활성화 함수를 거쳐 이진분류를 위한 확률을 뱉어내는 구조입니다. 여기서 V는 종목 개수, M은 임베딩 벡터의 크기입니다. 즉 학습이 완료된 임베딩 매트릭스의 각 행이 각 종목별 임베딩이 되는 구조입니다. 중심 종목과 주변 종목 벡터의 내적이 시그모이드를 거쳐 예측 라벨을 갖게 되면 실제 라벨과의 로스를 구하고 그것이 역전파되어 웨이트가 업데이트됩니다. 그리고 이 모델에 single layer stock2vec이라는 이름을 붙여주었습니다.

텐서플로우 프레임워크로 간단하게 모델을 구축할 수 있었고, 다행히 코스피 stock2vec과 코스닥 stock2vec모두 로스가 수렴하는 모습을 보여주었습니다. 코스피 stock2vec은 윈도우를 10으로, 코스닥 stock2vec은 윈도우를 5로 두었을 때 가장 결과가 좋았습니다.

그럼 지금부터 실제 벡터간 유사도 결과를 보여드리도록 하겠습니다. 

저는 임베딩벡터를 128차원으로 뽑았습니다. 보이시는 플랏은 T-SNE라는 방식을 활용해 고차원 벡터를 2차원으로 함축해서 시각한 것이고, 각 색깔은 업종코드를 의미합니다. 업종코드가 나름의 군집을 가지고 있지만 완전히 분류되지는 않은 것을 보아, 업종별 유사종목 추출과 완전히 다르게 벡터 임베딩이 잘 완성되었음을 볼 수 있습니다. 

이러한 종목 임베딩을 대내적으로, 그리고 대외적으로 활용할 수 있는 방안을 간단하게 제시해보겠습니다. 우선 최근에 오픈한 종목탐험 서비스처럼 종목간 관계를 대시보드 형태로 만들어 대내 서비스로 오픈할 수 있습니다. 배경지식이나 직감만으로는 떠올리기 어려운 유사한 종목들을 임베딩 벡터 유사도를 통해서 찾아낸다면 추가적인 인사이트가 될 수 있습니다. 또한 종목 정보 임베딩은 단순한 종목명 단어 임베딩과 다른, 가격흐름에 의한 종합적인 정보를 담은 임베딩이기 때문에 향후 분석이나 모델링의 새로운 변수로 활용할 수 있으리라 생각합니다. 

대외적으로는 MTS에 삽입되는 새로운 콘텐츠로 활용할 여지가 있다고 생각합니다. 어떤 고객이 종목을 매수하거나 오랫동안 그 종목의 정보를 탐색하는 트리거가 감지된다면 임베딩 벡터에 기반한 유사 종목을 팝업하면서 이 종목에 대한 정보도 찾아보라는 푸쉬알림을 보낼 수 있습니다. 이전에는 생각하지 못했던 종목들이 제시될 경우 충분히 흥미를 유발하게 되고, 이를 통한 MTS 체류시간 증대가 기대됩니다. 또한 앞서 말씀드린 종목 관계 대시보드 자체를 콘텐츠화 한다면 특히 다이렉트 인덱싱 등 고객이 적극적으로 상품설계에 개입되는 상품에서 사용을 유도함으로써 새로운 흥미거리를 줄 수 있습니다. 

이로써 발표를 마치겠습니다. 짧은 시간 동안 생각했던 것보다 좋은 임베딩이 뽑히긴 했지만, 원래 하고 싶었던 코스피 상장 종목과 코스닥 상장 종목을 함께 연결하는 모델링을 완료하지 못해서 아쉬움이 남습니다. 연수를 잘 끝내고 빅데이터센터로 돌아오게 된다면, 지금보다 더 풍부해진 여러가지 배경지식을 활용해서 이를 고도화해보고 싶은 마음이 남습니다. 발표 들어주셔서 감사합니다. 
